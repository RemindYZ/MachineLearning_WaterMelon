<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>
# C03-线性模型
## 3.1 基本形式
* 给定由*d*个属性描述的示例\\(\vec{x}=(x_1,x_2,...,x_d)\\)，其中\\(x_i\\)是\\(\vec{x}\\)在第*i*个属性上的取值，线性模型(linear model)试图学得一个通过属性的线性组合来进行预测的函数，即$$f(\vec{x}=\omega_1x_1+\omega_2x_2+...+\omega_dx_d+b)$$用向量形式写成$$f(\vec{x})=\vec{\omega}^T\vec{x}+b$$其中$$\vec{\omega}=(\omega_1,\omega_2,...,\omega_d)$$
## 3.2 线性回归
* 多元线性回归(multivariate linear regression)$$f(\vec{x} _i)=\vec{\omega}^T\vec{x} _i+b _i$$使得\\(f(\vec{x} _i)\simeq y _i\\)
* 用最小二乘法对\\(\vec{\omega}\\)和*b*进行估计，令$$\vec{X}=\begin{pmatrix}
        x_{11} & x_{12} & \cdots & x_{1d} & 1\\\\
        x_{21} & x_{22} & \cdots & x_{2d} & 1\\\\
        \vdots & \vdots & \ddots & \vdots & \vdots\\\\
        x_{m1} & x_{m2} & \cdots & x_{md} & 1
        \end{pmatrix}
=
\begin{pmatrix}
\vec{x_1}^T & 1\\\\
\vec{x_2}^T & 1\\\\
\vdots & \vdots\\\\
\vec{x_m}^T & 1\\\\
\end{pmatrix}$$将标记也写成向量形式\\(\vec{y}=(y_1,y_2,y_3...,y_m)\\)，有$$\widehat{\vec{\omega}}^*=argmin_{\vec{\omega}}(\vec{y}-\vec{X}\widehat{\vec{\omega}})^T(\vec{y}-\vec{X}\widehat{\vec{\omega}})$$
* 当\\(\vec{X}^T\vec{X}\\)为满秩矩阵(full-rank matrix)或者正定矩阵(positive definite matrix)时，有$$\widehat{\vec{\omega}}^*=(\vec{X}^T\vec{X})^{-1}\vec{X}^T\vec{y}$$
* 如果\\(\vec{X}^T\vec{X}\\)不是满秩矩阵，一般会引入正则化(regularization)
* 更一般地，考虑单调可微函数\\(g(·)\\)，令$$y=g^{-1}(\vec{\omega}^T\vec{x}+b)$$
## 3.3 对数几率回归
* 对于分类任务，在上述的广义模型中，，只需要找一个单调可微函数将分类任务的真实标记\\(y\\)与线性回归模型的预测值联系起来，一般是使用sigmoid function或者logistic function：$$y=\frac{1}{1+e^{-z}}$$即$$y=\frac{1}{1+e^{-(\vec{\omega}^T\vec{x}+b)}}$$可以变化为$$ln{\frac{y}{1-y}}=\vec{\omega}^T\vec{x}+b$$\\(y\\)可以视为样本预测结果为正例的可能性，\\(1-y\\)是反例的可能性
* 将\\(y\\)视为类后验概率估计\\(p(y=1|\vec{x})\\)，有$$ln{\frac{p(y=1|\vec{x})}{p(y=0|\vec{x})}}=\vec{\omega}^T\vec{x}+b$$
显然有
\begin{aligned}
&p(y=1|\vec{x})=\frac{e^{\vec{\omega}^T\vec{x}+b}}{1+e^{\vec{\omega}^T\vec{x}+b}}\\\\
&p(y=0|\vec{x})=\frac{1}{1+e^{\vec{\omega}^T\vec{x}+b}}
\end{aligned}
通过极大似然法(maximum likelihood method)来估计\\(\vec{\omega}^T\\)和\\(b\\)。
给定数据集\\(\lbrace(\vec{x} _i,y _i)\rbrace^m _{i=1}\\)，对数几率回归模型最大化“对数似然”(log-likelihood)$$l(\vec{\omega},b)=\sum _{i=1}^mlnp(y _i|\vec{x} _i;\vec{\omega},b)$$令\\(\vec{\beta}=(\vec{\omega};b)\\)，\\(\hat{\vec{x}}=(\vec{x};1)\\)，\\(p _1(\hat{\vec{x}};\vec{\beta})=p(y=1|\hat{\vec{x}};\vec{\beta})\\)，\\(p _0(\hat{\vec{x}};\vec{\beta})=p(y=0|\hat{\vec{x}};\vec{\beta})=1-p _1(\hat{\vec{x}};\vec{\beta})\\)，有$$p(y _i|\vec{x} _i;\vec{\omega},b)=y _ip _1(\hat{\vec{x} _i};\vec{\beta})+(1-y _i)p _0(\hat{\vec{x}} _i;\vec{\beta})$$于是，最大化对数似然等价于最小化下式（注意到\\(y _i\in \lbrace 0,1\rbrace\\)）:$$l(\vec{\beta})=\sum _{i=1}^m(-y _i\vec{\beta}^T\hat{\vec{x}} _i+ln(1+e^{\vec{\beta}\hat{\vec{x}} _i}))$$这是关于\\(\vec{\beta}\\)的高阶可导连续凸函数，可使用经典数值优化算法如梯度下降法(gradient descent method)、牛顿法(Newton method)等都可以求最优解，得到$$\vec{\beta}^*=argmin _{\vec{\beta}}l(\vec{\beta})$$
* 以牛顿法为例，迭代公式如下：$$\vec{\beta}^{t+1}=\vec{\beta}^t-(\frac{\partial^2l(\vec{\beta})}{\partial\vec{\beta}\partial\vec{\beta}^T})^{-1}\frac{\partial l(\vec{\beta})}{\partial\vec{\beta}}$$
其中
$$
\frac{\partial l(\vec{\beta})}{\partial \vec{\beta}}=-\sum _{i=1}^m\hat{\vec{x}} _i(y _i-p _1(\hat{\vec{x}} _i;\vec{\beta}))
$$
$$
\frac{\partial^2l(\vec{\beta})}{\partial\vec{\beta}\partial\vec{\beta}^T}=\sum _{i=1}^m\hat{\vec{x}} _i\hat{\vec{x}} _i^Tp _1(\hat{\vec{x}} _i;\vec{\beta})(1-p _1(\hat{\vec{x}} _i;\vec{\beta}))
$$
## 3.4 线性判别分析(Linear Discriminant Analysis, LDA)
* LDA的思想：给定训练样例集，将样例投影到一条直线上，使得同类样例的投影点尽可能接近，异类样例的投影点尽可能远离。在对新样例进行分类时，先将其投影到该条直线上，再根据投影点的位置来确定新的类别
* 给定数据集\\(D=\lbrace(\vec{x} _i,y _i)\rbrace^m _{i=1}\\)，\\(y _i\in\lbrace 0, 1\rbrace\\)，令\\(\vec{X} _i、\vec{\mu} _i、\vec{\Sigma} _i\\)分别表示第\\(i\in\lbrace 0, 1\rbrace\\)类的实例集合、均值向量、协方差矩阵。若将数据投影到直线上，则两类样本的中心在直线上的投影分别为\\(\vec{\omega}^T\vec{\mu} _0和\vec{\omega}^T\vec{\mu} _1\\)，协方差分别为\\(\vec{\omega}^T\vec{\Sigma} _0\vec{\omega}和\vec{\omega}^T\vec{\Sigma} _1\vec{\omega}\\)，那么最大化目标为
$$
J=\frac{||\vec{\omega}^T\vec{\mu} _0-\vec{\omega}^T\vec{\mu} _1|| _2^2}{\vec{\omega}^T(\vec{\Sigma} _0+\vec{\Sigma} _1)\vec{\omega}}
$$
* 定义“类内散度矩阵”(witnin-class scatter matrix)：
\begin{equation}
\begin{aligned}
\vec{S} _{\omega} &=\vec{\Sigma} _0+\vec{\Sigma} _1 \\\\
&=\sum _{\vec{x}\in X _0}(\vec{x}-\vec{\mu} _0)(\vec{x}-\vec{\mu} _0^T)+\sum _{\vec{x}\in X _1}(\vec{x}-\vec{\mu} _1)(\vec{x}-\vec{\mu} _1^T)
\end{aligned}
\end{equation}
定义“类间散度矩阵”(between-class scatter matrix)：$$\vec{S} _b=(\vec{\mu} _0-\vec{\mu} _1)(\vec{\mu} _0-\vec{\mu} _1)^T$$最大化目标重写为：$$J=\frac{\vec{\omega}^T\vec{S} _b\vec{\omega}}{\vec{\omega}^T\vec{S} _{\omega}\vec{\omega}}$$
* 注意到如果\\(\vec{\omega}\\)是一个解，那么\\(\alpha\vec{\omega}\\)也是一个解，故不失一般性，令\\(\vec{\omega}^T\vec{S} _{\omega}\vec{\omega}=1\\)，则上式等价于
\begin{equation}
\begin{aligned}
min _{\vec{\omega}} \qquad &-\vec{\omega}^T\vec{S} _b\vec{\omega} \\\\
s.t. \qquad &\vec{\omega}^T\vec{S} _{\vec{\omega}}\vec{\omega}=1
\end{aligned}
\end{equation}
由拉格朗日乘子法上式等价于$$\vec{S} _b\vec{\omega}=\lambda\vec{S} _{\omega}\vec{\omega}$$其中\\(\lambda\\)是拉格朗日乘子，注意到\\(\vec{S} _b\vec{\omega}\\)的方向恒为\\(\vec{\mu} _0-\vec{\mu} _1\\)，不妨令$$\vec{S} _b\vec{\omega}=\lambda(\vec{\mu} _0-\vec{\mu} _1)$$即有$$\vec{\omega}=\vec{S} _{\omega}^{-1}(\vec{\mu} _0-\vec{\mu} _1)$$
考虑到数值解的稳定性，在实践中通常对\\(\vec{S} _\omega\\)进行奇异值分解，即\\(\vec{S} _\omega=\vec{U}\vec{\Sigma}\vec{V}^T\\)。在根据\\(\vec{S} _\omega^{-1}=\vec{V}\vec{\Sigma}^{-1}\vec{U}^T\\)计算逆矩阵
* LDA可以推广到多分类任务中，也常常被视为一种经典的监督降维技术
## 3.5 多分类学习
* 有些二分类学习方法可以直接推广到多分类，但在更多情形下，我们是基于一些基本策略，利用二分类学习器来解决多分类问题。
* 不失一般性，考虑*N*个类别\\(C _1,C _2, C _3,\cdots ,C _N\\)，多分类学习的基本思路是“拆解法”，即将多分类问题拆为若干个二分类任务求解。最经典的拆分策略有三种：OvO、OvR、MvM

![](./picture/C03/OvOvsOvR.png)
* OvR只需训练*N*个分类器，而OvO需训练*N(N-1)/2*个分类器，因此OvO的存储开销和时间开销通常比OvR大。但是OvR每个分类器都需要全部的训练样例而OvO的每个分类器只需要用到两个类的样例，故在类别很多的时候，OvO的训练时间开销通常比OvR更小。至于预测性能，则取决于具体的数据分布，在多数情形下两者差不多
* MvM每次讲若干个类作为正类，若干个类作为反类.MvM的正反类需要通过特殊设计，不能随意选择，常见的技术是“纠错输出码”(Error Correcting Output Codes, ECOC)。
* ECOC的步骤一般分为两步，1.编码：对*N*个类别做*M*次划分，每次划分将一部分类划分为正类，一部分划分为反类，从而形成一个二分类训练集，这样一共产生*M*个训练集，可训练出*M*个分类器。2.解码：*M*个分类器分别对测试样例进行预测，这些预测标记组成一个编码，将这个预测编码与每个类别各自的编码进行比较，返回其中距离最小的类别作为最终预测结果

![](./picture/C03/ECOC.png)
## 3.6 类别不平衡问题(class-imbalance)
* 欠采样：去除一些样例使得每个类别的样例均衡(EasyEnsemble)
* 过采样：增加一些样例使得每个类别的样例均衡(SMOTE)
* 阈值移动：再缩放或者再平衡，这也是代价敏感学习的基础(cost-sensitive learning)
