<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>
# C02-模型评估与选择
## 2.1 经验误差与过拟合
* 如果在m个样本中有a个样本分类错误，则错误率(error rate)：\\(E=\frac{a}{m}\\)，精度(accuracy)：\\(A=1-\frac{a}{m}\\)
* 学习器在训练集上的误差称为训练误差(training error)或者经验误差(empirical error)，在新样本上的误差称为泛化误差(generalization)
* 过拟合(overfitting)，欠拟合(underfitting)
## 2.2 评估方法
使用一个测试集(testing set)来测试学习器对新样本的判别能力，然后以测试集上的测试误差(testing error)作为泛化误差的近似。
### 2.2.1 留出法(hold out)
* 留出法直接将数据集*D*划分为两个互斥的集合，其中一个集合作为训练集*S*，另一个作为测试集*T*，即\\(D=S\cup T,S\cap T=\Phi\\)，在*S*上训练出模型后，用*T*来评估其测试误差，作为对泛化误差的估计
* 训练集与测试集的划分要注意尽可能保持数据分布的一致性
* 单次留出法得到的估计结果往往不够稳定可靠，一般采用若干次随机划分，求平均作为评估结果
### 2.2.2 交叉验证法(cross validation)
* 先将数据集*D*划分为k个大小相似的互斥子集，即\\(D=D_1\cup D_2\cup ...\cup D_k , D_i\cap D_j =\Phi (i\ne j)\\)，每个子集都尽可能保持数据分布的一致性，每次用k-1个子集的并集作为训练集，余下的子集作为测试集，最终返回这k个测试结果的均值，又称k折交叉验证(k-fold cross validation)
* 假定数据集*D*中包含m个样本，若令\\(k=m\\)，则得到留一法(Leave-One-Out)，问题是数据集较大时，计算开销会非常大
### 2.2.3 自助法(bootstrapping)
* 给定包含m个样本的数据集*D*，对它进行采样产生数据集*D'*：每次随机从*D*中挑选一个样本将其拷贝放入*D'*，然后再将该样本放回初始集合，使得该样本仍然可以被采集到，重复m次后，得到包含m个样本的数据集*D'*。用*D'*作为训练集，*D\D'*为测试集
* 数据集小，难以有效划分训练和测试集时很有用
## 2.3 性能度量(performance measure)
在预测任务中，给定样例集\\(D=\\{(\vec{x_1},y_1),(\vec{x_2},y_2),...,(\vec{x_m},y_m)\\}\\)，回归任务最常用的性能度量时均方误差(mean squared error)$$E(f;D)=\frac{1}{m}\sum_{i=1}^{m}{(f(\vec{x_i})-y_i)^2}$$更一般的，对于数据分布*D*和概率密度函数*p*，均方误差可描述为$$E(f;D)=\int_{\vec{x}\in D}{(f(\vec{x})-y)^{2}p(\vec{x})d\vec{x}}$$
### 2.3.1 错误率与精度
### 2.3.2 查准率，查全率与F1
混淆矩阵(confusion matrix)

![](./picture/C02/picture1.png)
* 查准率*P*$$P=\frac{TP}{TP+FP}$$
* 查全率*R*$$R=\frac{TP}{TP+FN}$$
* F1度量:是基于查准率与查全率的调和平均$$F1=\frac{2\times p\times R}{P+R}$$
* \\(F_\beta\\)度量：是加权调和平均$$F_\beta=\frac{(1+\beta^2)\times P\times R}{(\beta^2\times P)+R}$$
### 2.3.3 ROC和AUC
* 重视查准率，选择排序靠前的位置进行截断，重视查全率，则选择靠后的位置进行截断
* ROC纵轴是TPR(True Positive Rate)，横轴是FPR(False Positive Rate)，定义为$$TPR=\frac{TP}{TP+FN}$$$$FPR=\frac{FP}{FP+TN}$$
* AUC为ROC曲线围成的面积，可以通过比较AUC的大小来判断模型的好坏
### 2.3.4 代价敏感错误率与代价曲线
* 通过为错误赋予非均等代价(unequal cost)设定代价矩阵，相当于在计算损失函数时为错误加权
## 2.4 比较检验
## 2.5 偏差与方差
对测试样本\\(\vec{x}\\)，令\\(y_D\\)为\\(\vec{x}\\)在数据集中的标记，\\(y\\)为\\(\vec{x}\\)的真实标记，\\(f(\vec{x};D)\\)为训练集\\(D\\)上学到的模型*f*在\\(\vec{x}\\)上的预测输出。以回归任务为例，学习算法的期望预测是$$\bar{f}(\vec{x})=E_D[f(\vec{x};D)]$$使用样本数相同的不同训练集产生的方差为$$var(\vec{x})=E_D[(f(\vec{x};D)-\bar{f}(\vec{x}))^2]$$噪声为$$\epsilon^2=E_D[(y_D-y)^2]$$期望输出与真实标记的差别称为偏差(bias)，即$$bias^2(\vec{x})=(\bar{f}(\vec{x})-y)^2$$假定噪声期望为零，即\\(E_D[y_D-y]=0\\)，有$$E(f;D)=bias^2(\vec{x})+var(\vec{x})+\epsilon^2$$